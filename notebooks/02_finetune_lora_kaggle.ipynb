{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14364178,"sourceType":"datasetVersion","datasetId":9172452},{"sourceId":6104837,"sourceType":"datasetVersion","datasetId":3497143}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q --no-deps --upgrade pyarrow==14.0.1 transformers==4.40.0 tokenizers==0.19.1 datasets==2.14.6 peft==0.11.1 accelerate==0.27.0\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T17:03:06.656855Z","iopub.execute_input":"2026-01-01T17:03:06.657443Z","iopub.status.idle":"2026-01-01T17:03:13.699135Z","shell.execute_reply.started":"2026-01-01T17:03:06.657414Z","shell.execute_reply":"2026-01-01T17:03:13.698253Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.0/38.0 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import torch\n\nprint(\"GPU Available:\", torch.cuda.is_available())\nif torch.cuda.is_available():\n    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n    print(\"GPU Memory:\", torch.cuda.get_device_properties(0).total_memory / 1e9, \"GB\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T17:04:38.403233Z","iopub.execute_input":"2026-01-01T17:04:38.403846Z","iopub.status.idle":"2026-01-01T17:04:41.728148Z","shell.execute_reply.started":"2026-01-01T17:04:38.403817Z","shell.execute_reply":"2026-01-01T17:04:41.727513Z"}},"outputs":[{"name":"stdout","text":"GPU Available: True\nGPU Name: Tesla T4\nGPU Memory: 15.828320256 GB\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import json\nfrom datasets import Dataset\n\n# Your Bengali empathetic conversation data\ntrain_data = [\n    {\"text\": \"Below is a conversation between a user and an empathetic assistant.\\n\\n### User:\\nআমি খুবই দুঃখী বোধ করছি, কিছুই ভালো লাগছে না।\\n\\n### Assistant:\\nআমি বুঝতে পারছি আপনি খুব কঠিন সময়ের মধ্য দিয়ে যাচ্ছেন। এভাবে অনুভব করা স্বাভাবিক, কিন্তু আপনি একা নন।\"},\n    {\"text\": \"Below is a conversation between a user and an empathetic assistant.\\n\\n### User:\\nআমার পড়াশোনা ভালো যাচ্ছে না, আমি নিজেকে ব্যর্থ মনে করছি।\\n\\n### Assistant:\\nনিজেকে ব্যর্থ মনে হওয়া খুব কষ্টের অনুভূতি। কিন্তু একটি খারাপ সময় আপনার সব দক্ষতা নষ্ট করে না।\"},\n    {\"text\": \"Below is a conversation between a user and an empathetic assistant.\\n\\n### User:\\nআমার পরিবার আমাকে বুঝে না বলে মনে হয়।\\n\\n### Assistant:\\nপরিবারের দ্বারা না বোঝা হওয়া সত্যিই কষ্টদায়ক। আপনার অনুভূতিগুলো শান্তভাবে তুলে ধরার চেষ্টা করুন।\"},\n    {\"text\": \"Below is a conversation between a user and an empathetic assistant.\\n\\n### User:\\nআমার কোনো বন্ধু নেই মনে হয়, আমি একা বোধ করি।\\n\\n### Assistant:\\nএকাকিত্ব খুব ভারী অনুভূতি হতে পারে। ধীরে ধীরে মানুষদের সাথে ছোট ছোট আলাপ শুরু করুন।\"},\n    {\"text\": \"Below is a conversation between a user and an empathetic assistant.\\n\\n### User:\\nআমি সব সময় ভবিষ্যৎ নিয়ে চিন্তায় থাকি।\\n\\n### Assistant:\\nভবিষ্যৎ নিয়ে দুশ্চিন্তা করা খুব স্বাভাবিক। বর্তমানে আপনি কী নিয়ন্ত্রণ করতে পারেন সেদিকে ফোকাস করুন।\"},\n    {\"text\": \"Below is a conversation between a user and an empathetic assistant.\\n\\n### User:\\nআমার কাজের প্রতি কোন আগ্রহ নেই, সবকিছু ক্লান্তিকর লাগে।\\n\\n### Assistant:\\nদীর্ঘদিন ধরে ক্লান্তি মানসিক স্বাস্থ্যের লক্ষণ হতে পারে। নিজের প্রতি সহানুভূতিশীল হোন।\"},\n    {\"text\": \"Below is a conversation between a user and an empathetic assistant.\\n\\n### User:\\nআমি ছোট ছোট ভুল করলেই নিজেকে ঘৃণা করি।\\n\\n### Assistant:\\nসবাই ভুল করে। ভুল থেকে শিখে এগিয়ে যাওয়ার চেষ্টা করুন।\"},\n    {\"text\": \"Below is a conversation between a user and an empathetic assistant.\\n\\n### User:\\nসবাই যেন আমার থেকে অনেক এগিয়ে গেছে, আমি পিছিয়ে পড়েছি।\\n\\n### Assistant:\\nপ্রত্যেকের যাত্রা আলাদা। নিজের ছোট অগ্রগতি চিহ্নিত করার চেষ্টা করুন।\"},\n    {\"text\": \"Below is a conversation between a user and an empathetic assistant.\\n\\n### User:\\nআমি আমার ক্যারিয়ার নিয়ে খুবই অনিশ্চিত বোধ করছি।\\n\\n### Assistant:\\nক্যারিয়ার নিয়ে অনিশ্চয়তা অনেকের জীবনেই আসে। ছোট পদক্ষেপ নিয়ে এগিয়ে যান।\"},\n    {\"text\": \"Below is a conversation between a user and an empathetic assistant.\\n\\n### User:\\nআমি আমার ভুলের জন্য নিজেকে ক্ষমা করতে পারব বলে মনে হয় না।\\n\\n### Assistant:\\nগভীর অনুশোচনা ভারী হতে পারে। নিজেকে ধীরে ধীরে ক্ষমা করা একটি প্রক্রিয়া।\"},\n]\n\nval_data = [\n    {\"text\": \"Below is a conversation between a user and an empathetic assistant.\\n\\n### User:\\nআমার সাথে কেউ খোলামেলা কথা বলতে চায় না।\\n\\n### Assistant:\\nএমন অনুভূতি খুব একাকিত্বের জন্ম দিতে পারে। এমন কাউকে খুঁজুন যিনি শুনবেন।\"},\n    {\"text\": \"Below is a conversation between a user and an empathetic assistant.\\n\\n### User:\\nমানুষ আমাকে সবসময় ভুল বোঝে।\\n\\n### Assistant:\\nভুল বোঝাবুঝি হতাশাজনক। আপনি আপনার সত্য জানেন এবং সেটাই গুরুত্বপূর্ণ।\"},\n]\n\n# Create HuggingFace Datasets\ntrain_ds = Dataset.from_list(train_data)\nval_ds = Dataset.from_list(val_data)\n\nprint(f\"✓ Training examples: {len(train_ds)}\")\nprint(f\"✓ Validation examples: {len(val_ds)}\")\nprint(f\"✓ Sample: {train_data[0]}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T17:04:43.947880Z","iopub.execute_input":"2026-01-01T17:04:43.948795Z","iopub.status.idle":"2026-01-01T17:04:45.666402Z","shell.execute_reply.started":"2026-01-01T17:04:43.948764Z","shell.execute_reply":"2026-01-01T17:04:45.665816Z"}},"outputs":[{"name":"stdout","text":"✓ Training examples: 10\n✓ Validation examples: 2\n✓ Sample: {'text': 'Below is a conversation between a user and an empathetic assistant.\\n\\n### User:\\nআমি খুবই দুঃখী বোধ করছি, কিছুই ভালো লাগছে না।\\n\\n### Assistant:\\nআমি বুঝতে পারছি আপনি খুব কঠিন সময়ের মধ্য দিয়ে যাচ্ছেন। এভাবে অনুভব করা স্বাভাবিক, কিন্তু আপনি একা নন।'}\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nfrom peft import LoraConfig, get_peft_model\n\nprint(\"✓ Loading Model...\")\nmodel_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n\n# 1. Tokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ntokenizer.pad_token = tokenizer.eos_token\n\n# 2. Model (float16 to fit T4 GPU easily)\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    torch_dtype=torch.float16,\n    device_map=\"auto\"\n)\n\n# 3. LoRA Configuration\nconfig = LoraConfig(\n    r=16,\n    lora_alpha=16,\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)\n\n# 4. Apply LoRA\nmodel = get_peft_model(model, config)\nmodel.print_trainable_parameters()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T17:05:33.245171Z","iopub.execute_input":"2026-01-01T17:05:33.245468Z","iopub.status.idle":"2026-01-01T17:06:03.850260Z","shell.execute_reply.started":"2026-01-01T17:05:33.245443Z","shell.execute_reply":"2026-01-01T17:06:03.849609Z"}},"outputs":[{"name":"stderr","text":"2026-01-01 17:05:41.949929: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767287142.115074      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1767287142.161152      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1767287142.543277      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767287142.543315      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767287142.543317      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767287142.543319      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"name":"stdout","text":"✓ Loading Model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f4e8225395e4f3e91ad5ad9d03244cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c28450301f04f0ea71151701aa7fc3e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5deaf647feb247fc8ce06a380c4cdf84"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12bec11e99ab4498bcdc732c9d2ce117"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbe21d25527e4da39d52865a93f923b6"}},"metadata":{}},{"name":"stderr","text":"`torch_dtype` is deprecated! Use `dtype` instead!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"619157923ba6473e91d64d4430469b4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"188432a2171a431784146efa821eb8af"}},"metadata":{}},{"name":"stdout","text":"trainable params: 4,505,600 || all params: 1,104,553,984 || trainable%: 0.4079\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"print(\"✓ Tokenizing data...\")\n\ndef tokenize_function(examples):\n    \"\"\"Tokenize text and set labels for causal language modeling\"\"\"\n    tokenized = tokenizer(\n        examples[\"text\"],\n        padding=\"max_length\",\n        max_length=256,          # Smaller sequence length to fit in memory\n        truncation=False,        # Do NOT truncate (requirement)\n        return_tensors=None\n    )\n    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n    return tokenized\n\n# Tokenize train and validation datasets\ntokenized_train = train_ds.map(tokenize_function, batched=True, remove_columns=[\"text\"])\ntokenized_val = val_ds.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n\nprint(f\"✓ Tokenized Train: {len(tokenized_train)} examples\")\nprint(f\"✓ Tokenized Val: {len(tokenized_val)} examples\")\nprint(f\"✓ First sample keys: {list(tokenized_train[0].keys())}\")\nprint(f\"✓ First sample shape: input_ids={len(tokenized_train[0]['input_ids'])}, labels={len(tokenized_train[0]['labels'])}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T17:07:13.846963Z","iopub.execute_input":"2026-01-01T17:07:13.847894Z","iopub.status.idle":"2026-01-01T17:07:13.955273Z","shell.execute_reply.started":"2026-01-01T17:07:13.847859Z","shell.execute_reply":"2026-01-01T17:07:13.954484Z"}},"outputs":[{"name":"stdout","text":"✓ Tokenizing data...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6adff91341cb4fdbbc863872bd2dcf82"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac914368b1174773aff89886be4c707a"}},"metadata":{}},{"name":"stdout","text":"✓ Tokenized Train: 10 examples\n✓ Tokenized Val: 2 examples\n✓ First sample keys: ['input_ids', 'attention_mask', 'labels']\n✓ First sample shape: input_ids=256, labels=256\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\nprint(\"✓ Setting up Training...\")\n\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    num_train_epochs=3,                # 3 epochs\n    per_device_train_batch_size=1,     # Small batch size for safety\n    gradient_accumulation_steps=4,     # Accumulate gradients to simulate larger batch\n    learning_rate=2e-4,                # Standard LoRA learning rate\n    logging_steps=1,\n    fp16=False,                        # Disable mixed precision to avoid conflict\n    save_strategy=\"no\",                # Don't save checkpoints to save disk space\n    report_to=[],                      # Disable wandb/logging integrations\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_val,\n)\n\nprint(\"✓ Starting Training...\")\ntrainer.train()\nprint(\"✓ Training Finished!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T17:07:52.745361Z","iopub.execute_input":"2026-01-01T17:07:52.745688Z","iopub.status.idle":"2026-01-01T17:07:59.416546Z","shell.execute_reply.started":"2026-01-01T17:07:52.745659Z","shell.execute_reply":"2026-01-01T17:07:59.415895Z"}},"outputs":[{"name":"stdout","text":"✓ Setting up Training...\n✓ Starting Training...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [9/9 00:03, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>5.001500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>4.061000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>4.075300</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>3.108200</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>2.945600</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>2.579300</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>2.456600</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>2.015600</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>1.854600</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"✓ Training Finished!\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import math\n\nprint(\"✓ Running evaluation on validation set...\")\neval_results = trainer.evaluate()\n\nval_loss = eval_results[\"eval_loss\"]\nperplexity = math.exp(val_loss)\n\nprint(\"Validation Loss:\", val_loss)\nprint(\"Perplexity:\", perplexity)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T17:08:46.455108Z","iopub.execute_input":"2026-01-01T17:08:46.455799Z","iopub.status.idle":"2026-01-01T17:08:46.592340Z","shell.execute_reply.started":"2026-01-01T17:08:46.455770Z","shell.execute_reply":"2026-01-01T17:08:46.591766Z"}},"outputs":[{"name":"stdout","text":"✓ Running evaluation on validation set...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1/1 : < :]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Validation Loss: 2.39481520652771\nPerplexity: 10.966171394939236\n","output_type":"stream"}],"execution_count":6}]}